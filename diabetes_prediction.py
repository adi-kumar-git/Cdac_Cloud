# -*- coding: utf-8 -*-
"""Diabetes_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WcnkuRwivAOOLcbjVrNwvEtP1x7hei_z
"""

'''The reason why some values in the diabetes dataset (from sklearn.datasets) appear negative or zero is because the feature variables have been mean-centered and scaled. Let me explain this in detail:

What is Mean-Centering and Scaling?
Mean-Centering:
The mean of each feature column is subtracted from each data point in that column. As a result, the mean of the column becomes 0.

Scaling:
The centered values are then scaled so that the sum of the squares of each feature column equals 1. This is done by dividing each feature by a constant that involves the standard deviation and the square root of the number of samples (‚àön_samples).

The purpose is to standardize the data.

Why Do Some Values Appear Negative or Zero?
Negative Values:
After centering, some values fall below the mean, which results in negative numbers. This is expected when applying mean-centering.

Zero Values:
If a data point equals the mean of that column, it becomes exactly 0 after mean-centering.

Continuous Target Variable:
The target variable (disease progression) is not transformed. It remains in its original form because it is the value you are trying to predict, so it is continuous and unstandardized.

Example Explanation
Here‚Äôs how it works conceptually for a single column:

Suppose the bmi column has values: [20, 25, 30, 35].
Calculate the mean: mean = 27.5.
Subtract the mean from each value (mean-centering):
[20 - 27.5, 25 - 27.5, 30 - 27.5, 35 - 27.5] ‚Üí [-7.5, -2.5, 2.5, 7.5].
Scale these values so their sum of squares equals 1.
As a result, some values become negative, and the column is standardized.

Why Standardize the Features?
Standardizing the features makes the data easier to work with for machine learning algorithms because:

It ensures all features are on the same scale.
It reduces bias due to different ranges of data.
Algorithms like Linear Regression, SVMs, and Neural Networks perform better on standardized data.
Summary
The predictive features are mean-centered and scaled. This transformation causes values to appear as negative, zero, or small positive numbers.
The target variable is continuous and unscaled, which is why it looks different.
Let me know if you want a demonstration with code to clarify further! üöÄ






You said:
what is preprocessing
ChatGPT said:
ChatGPT
Preprocessing in Machine Learning
Preprocessing refers to the steps taken to prepare raw data for use in a machine learning model. Raw data often contains inconsistencies, missing values, noise, or is not in a suitable format for training a model. Preprocessing transforms this raw data into a clean, structured, and meaningful format that algorithms can understand and process efficiently.

Why is Preprocessing Important?
Improves data quality for better model accuracy.
Ensures data is in the correct format for algorithms.
Handles missing values, outliers, and noise.
Scales and normalizes data for better performance in machine learning algorithms.
Common Preprocessing Techniques
Here are the most common preprocessing steps:

1. Handling Missing Data
Why: Missing values can lead to incorrect training or model failure.
Techniques:
Imputation: Replace missing values with the mean, median, or mode.
Example: missing_value = mean(column).
Removing rows/columns with too many missing values.
2. Encoding Categorical Data
Why: Most machine learning algorithms require numerical input.
Techniques:
Label Encoding: Convert categories to integers (e.g., Male = 0, Female = 1).
One-Hot Encoding: Represent categories as binary columns.
Example:
makefile
Copy code
Gender: Male, Female
‚Üí Male = [1, 0], Female = [0, 1].
3. Feature Scaling and Normalization
Why: Ensures features are on the same scale to prevent dominance of larger values.
Techniques:
Standardization (Z-score):
Centering the data (mean = 0, standard deviation = 1). Formula:
ùëã
‚Ä≤
=
ùëã
‚àí
mean
std¬†dev
X
‚Ä≤
 =
std¬†dev
X‚àímean
‚Äã

Min-Max Scaling: Scales values between 0 and 1. Formula:
ùëã
‚Ä≤
=
ùëã
‚àí
ùëã
min
ùëã
max
‚àí
ùëã
min
X
‚Ä≤
 =
X
max
‚Äã
 ‚àíX
min
‚Äã

X‚àíX
min
‚Äã

‚Äã

4. Removing Noise and Outliers
Why: Noise or outliers can reduce model accuracy.
Techniques:
Removing outliers using IQR (Interquartile Range) or Z-scores.
Using filters or statistical methods to clean noisy data.
5. Dimensionality Reduction
Why: Reduce the number of features to improve model efficiency and avoid overfitting.
Techniques:
PCA (Principal Component Analysis): Reduces dimensions while retaining maximum variance.
Feature Selection: Select only relevant features.
6. Data Transformation
Transform data into a suitable format:
Log Transformation: For skewed data.
Binning: Grouping continuous values into categories.
Mean-Centering: Making the mean of the feature 0.
7. Splitting Data
Divide the data into:
Training Set: Used to train the model.
Testing Set: Used to evaluate the model.
Optionally, a Validation Set for hyperparameter tuning.
Example of Preprocessing Code in Python
Here‚Äôs an example using sklearn:

python
Copy code
import pandas as pd
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.model_selection import train_test_split

# Load a dataset
data = pd.read_csv('data.csv')

# Handling Missing Data
data.fillna(data.mean(), inplace=True)

# Encoding Categorical Data
encoder = OneHotEncoder()
encoded_features = encoder.fit_transform(data[['Category']]).toarray()

# Feature Scaling
scaler = StandardScaler()
scaled_features = scaler.fit_transform(data[['Age', 'Salary']])

# Splitting the Data
X_train, X_test, y_train, y_test = train_test_split(scaled_features, data['Target'], test_size=0.2)
Summary
Preprocessing is an essential step to clean and prepare data for machine learning. It includes handling missing values, scaling features, encoding data, and splitting the dataset into training and testing sets.

Let me know if you need examples or explanations for specific preprocessing steps! '''

from sklearn.datasets import load_diabetes

df=load_diabetes()

df2=load_diabetes()

print(df["DESCR"])

df.target

df.data

import pandas as pd

df=pd.DataFrame(df.data, columns=df.feature_names)

#we dont need to do the scaling and onehotencoder because the data is alredy preprocessed

X=df



y=df2.target

from sklearn.model_selection import train_test_split

X_train, X_test ,y_train , y_test = train_test_split(X,y, test_size=0.3, random_state=48)

X.corr()

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(10,10))
sns.heatmap(X.corr(),annot=True)

from sklearn.tree import DecisionTreeRegressor

regressor = DecisionTreeRegressor()

regressor.fit(X_train, y_train)

y_predict=regressor.predict(X_test)

from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

accuracy1= r2_score(y_test, y_predict)

print("Accurace is {:.2f}".format(accuracy1))

print("R¬≤ Score: {:.2f}%".format(accuracy1* 100))

'''If your R¬≤ score is negative, it indicates that your model is performing worse than the mean baseline. This means the predictions from your model are farther from the actual values compared to simply predicting the mean of the target variable for every instance.

Common Reasons for Negative R¬≤ Score:
Overfitting:
The DecisionTreeRegressor may be overfitting the training data. This happens when the tree is too deep and learns noise instead of patterns.

Small Training Set:
With insufficient training data, the model does not generalize well on unseen data.

Incorrect Hyperparameters:
By default, the DecisionTreeRegressor does not limit the depth of the tree, which can cause overfitting.

Features Not Informative:
The input features may not be very predictive for the target variable.'''

#now by hyperparameter

param={
    "criterion" : ["squared_error","friedman_mse","absolute_error","poisson"],
    "splitter" : ["best","random"],
    "max_depth" : [1,2,3,4,5,10,15,20,25],
    "max_features" : ["auto","sqrt","log2"]
}

from sklearn.model_selection import GridSearchCV

regressor1 = DecisionTreeRegressor()

grid = GridSearchCV(regressor1, param_grid=param, cv=5, scoring="neg_mean_squared_error")

grid.fit(X_train,y_train)

grid.best_params_

import warnings
warnings.filterwarnings("ignore")

grid.best_score_

y_predict=grid.predict(X_test)

accuracy2=r2_score(y_test, y_predict)

print("accuracy after hypertuning {:.2f}%".format(accuracy2*100))

select_model = DecisionTreeRegressor(criterion='friedman_mse', max_depth=2, max_features='sqrt', splitter='best')

select_model.fit(X_train, y_train)

y_predict=select_model.predict(X_test)

accuracy3=r2_score(y_test, y_predict)

print("accuracy after hypertuning best parameters {:.2f}%".format(accuracy3*100))